<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kevin Kiley</title>
    <link>https://krkiley.github.io/</link>
      <atom:link href="https://krkiley.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Kevin Kiley</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 02 May 2022 14:12:46 -0400</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Kevin Kiley</title>
      <link>https://krkiley.github.io/</link>
    </image>
    
    <item>
      <title>Cohort Succession Explains Most Change in Literary Culture</title>
      <link>https://krkiley.github.io/publication/cohort-literary/</link>
      <pubDate>Mon, 02 May 2022 14:12:46 -0400</pubDate>
      <guid>https://krkiley.github.io/publication/cohort-literary/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Model-Based Method for Detecting Persistent Cultural Change Using Panel Data</title>
      <link>https://krkiley.github.io/publication/model-based-method/</link>
      <pubDate>Wed, 21 Apr 2021 14:12:46 -0400</pubDate>
      <guid>https://krkiley.github.io/publication/model-based-method/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SEM measure of stability</title>
      <link>https://krkiley.github.io/blog/sem-stability/</link>
      <pubDate>Mon, 04 May 2020 08:49:58 -0400</pubDate>
      <guid>https://krkiley.github.io/blog/sem-stability/</guid>
      <description>&lt;p&gt;My 
&lt;a href=&#34;https://krkiley.github.io/blog/nobody_changes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;previous post&lt;/a&gt; outlined perhaps the most basic approach to comparing the Settled Disposition Model (SDM) and Active Updating Model (AUM): counting whether there were more cases of persistent change than anticipated under the settled dispositions model. But that was not our first approach.&lt;/p&gt;
&lt;p&gt;We began the project by comparing two structural equation models, presented below, for each attitude and behavior measure in the GSS. We represent the difference between the two data-generating processes slightly differently in this presentation than in the paper. In this structure, we ask: Once we control for the average response across the three waves, are the residuals for adjacent waves correlated? If changes at each wave are more-or-less temporary or random departures (as assumed under the SDM), there should be no correlation between residuals once we control for a person&amp;rsquo;s mean. If people are changing in persisting ways (as assumed in the AUM), adjacent waves will have non-zero correlation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;diagrams.png&#34; alt=&#34;SEM diagrams&#34;&gt;&lt;/p&gt;
&lt;p&gt;To this end, the SEM for the active updating model (on the right) includes one more parameter than the settled dispositions model (on the left): a term that allows the covariance of the residuals for adjacent waves to be non-zero. This term constrained to be equal for both pairs of adjacent waves (1-2 and 2-3).&lt;/p&gt;
&lt;p&gt;Similar to what we do in the paper when we compare two regression models, one with a constraint and one without, we can compare the BICs of both structural equation models to estimate a probability that one model fits better than the other. That distribution is presented below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;semplot.png&#34; alt=&#34;Probabilities of active updatings&#34;&gt;&lt;/p&gt;
&lt;p&gt;In contrast to the distribution of probabilities we present in the paper, which found that about 60 percent of questions showed some evidence of persistence (or favoring the active updating model), the SEM approach finds only about 34 percent of questions show evidence of persistence. About two-thirds of questions are classified the same in both models. Almost all items that are classified differently in the two models show evidence of persistence in the regression model but no significant evidence of persistence in the SEM model. What explains the 58 items that differ between the two models?&lt;/p&gt;
&lt;p&gt;The model used in the paper, similar to the previous post, focuses primarily on using waves 1 and 2 to predict wave 3. In contrast, the SEM approach looks at the overall pattern of responses over all three waves and evaluates how well they conform to the two data-generating models.&lt;/p&gt;
&lt;p&gt;Consider the following example. We ask people a question with a binary (yes/no) response option. There are three types of cases with the same &amp;ldquo;mean&amp;rdquo; response (.66): 0-1-1, 1-0-1, and 1-1-0 (the converse patterns also exist: 1-0-0, 0-1-0, and 0-0-1). The regression approach only considers the first two patterns and evaluates whether the first occurs more often than the second. In the third pattern, both wave 1 and wave 2 make the same (wrong) prediction for wave 3, so they cannot help adjudicate the overall pattern. However, in the SEM context, the settled dispositions model actually predicts that all three of these patterns will occur in roughly the same proportion, while the active updating model predicts that the first and last patterns will each occur more often than the middle pattern.&lt;/p&gt;
&lt;p&gt;In the example above, if 0-1-1 occurs much more frequently than 1-0-1, but 1-1-0 occurs much less frequently, the SEM model will predict no persistence where the regression model will. In other words, the 1-1-0 patterns can &amp;ldquo;balance&amp;rdquo; out 0-1-1 patterns in the SEM approach.&lt;/p&gt;
&lt;p&gt;This appears to be the case for some of the variables that differ between the two models, such as the &amp;ldquo;abortion in the case of rape&amp;rdquo; question (abany). Of people who change between the first two waves, 111 revert to their wave 1 response while 149 persist in their new response, which appears to provide evidence for active updating in the regression model. However, the number of people who give a different response in wave 3 is only 128, weakening the evidence of persistence to make it non-significant.&lt;/p&gt;
&lt;p&gt;Second, the SEM approach does not include an intercept for each wave, which the regression approach used in the paper does. In this way, it is similar to the counting measure shown in the previous post. While one might expect that this would result in more evidence of persistence, as the SEM approach can capture population-wide change in a single direction that the regression approach does not, we actually see the opposite. In the regression model, a small group of people making large changes in one direction can make other people persist &lt;em&gt;relative to the population mean&lt;/em&gt; even when they do not change their responses.&lt;/p&gt;
&lt;p&gt;Despite these differences, it is important to note that the overall picture is quite similar to what we find in the paper (if it wasn&amp;rsquo;t, we probably wouldn&amp;rsquo;t have published the paper). When we look at the results of this approach, the approach we use in 
&lt;a href=&#34;https://krkiley.github.io/publication/measuring-change-and-stability-in-personal-culture-using-panel-data/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the paper&lt;/a&gt;, and the approach I outlined in the 
&lt;a href=&#34;https://krkiley.github.io/blog/nobody_changes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;previous post&lt;/a&gt;: for most items measuring during the GSS panels from 2006 to 2014, it is hard to make the case that some meaningful proportion of people changed their view in a persisting way.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Nobody (really) changes</title>
      <link>https://krkiley.github.io/blog/nobody_changes/</link>
      <pubDate>Tue, 28 Apr 2020 08:28:09 -0500</pubDate>
      <guid>https://krkiley.github.io/blog/nobody_changes/</guid>
      <description>&lt;p&gt;In my &lt;em&gt;American Sociological Review&lt;/em&gt; 
&lt;a href=&#34;https://journals-sagepub-com.proxy.lib.duke.edu/doi/full/10.1177/0003122420921538&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper with Steve Vaisey&lt;/a&gt; (open access version 
&lt;a href=&#34;https://osf.io/preprints/socarxiv/8za35/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;), we look for evidence that people make persisting changes in attitudes and behaviors in the 
&lt;a href=&#34;https://gssdataexplorer.norc.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;General Social Survey&lt;/a&gt;. We present one approach to measuring persistence in the paper, but we tested many approaches throughout the project. Over the next couple weeks I want go through some of the approaches we tried. And I&amp;rsquo;ll show how different approaches all produce the same result we find in the paper: persisting change in any kind of attitude is extremely rare in American adults.&lt;/p&gt;
&lt;p&gt;Our paper argues that, at the individual level, people follow one of two models of attitude formation: a settled dispositions model, in which changes are temporary and people revert to their baseline, and an active updating model, in which changes persist.&lt;/p&gt;
&lt;p&gt;A challenge of comparing these models is that in a three-wave survey context, both models can produce individuals who look like they are making persistent changes. For a simple example, consider one of the seven GSS questions about conditions under which people support legal access to abortion: &amp;ldquo;Please tell me whether or not you think it should be possible for a pregnant woman to obtain a legal abortion if the woman wants it for any reason.&amp;rdquo; Respondents could select &amp;ldquo;yes&amp;rdquo; or &amp;ldquo;no&amp;rdquo; as responses.&lt;/p&gt;
&lt;p&gt;Under the active updating model, a person who changed from saying &amp;ldquo;yes&amp;rdquo; at wave 1 to &amp;ldquo;no&amp;rdquo; at wave 2 should say &amp;ldquo;no&amp;rdquo; again at wave 3. Under the settled dispositions model, we should view it as equally likely that wave 1 or wave 2 is a temporary departure from the person&amp;rsquo;s baseline. The patterns &amp;ldquo;no-yes-yes&amp;rdquo; and &amp;ldquo;yes-no-yes&amp;rdquo; (and &amp;ldquo;yes-yes-no&amp;rdquo;) should be equally common because these deviations (the nos) are random. If &amp;ldquo;no-yes-yes&amp;rdquo; occurs as often as &amp;ldquo;yes-no-yes&amp;rdquo;, then the former does not provide any evidence of persistent change (or we have a hard time explaining the latter).&lt;/p&gt;
&lt;p&gt;As a result, we should guess that 50 percent of the time people who give different responses at waves 1 and 2 would say &amp;ldquo;yes&amp;rdquo; at wave 3 and 50 percent of the time they say &amp;ldquo;no.&amp;rdquo; In other words, we see people who look to be persisting (&amp;ldquo;no-yes-yes&amp;rdquo;) simply because their wave 1 response was a temporary (or random) departure from their baseline.&lt;/p&gt;
&lt;p&gt;Of the 2,297 people who responded to the abortion question over three waves, 424 (18 percent) gave different answers in waves 1 and 2. Under the settled dispositions model, in which deviations are equally likely in each wave, we would expect that 212 people would appear to be making persisting changes even when they are not, simply because of the three-wave structure.&lt;/p&gt;
&lt;p&gt;What we see is that 227 people show a pattern of persistence, or just 15 more than expected if the settled dispositions model generated the data. That is not a lot of people. Those 15 percent of people account for less than 1 percent of the total sample. So already we can say that persisting change in this item is substantively rare.&lt;/p&gt;
&lt;p&gt;Is that enough people to say that we see some evidence of persistence in the population? Would it be unusual to get that many people displaying evidence of persistence if there is no persistence in the population?&lt;/p&gt;
&lt;p&gt;A simple calculation of confidence interval for the proportion of changers persisting, where we use the number of people who change (424) as the sample size, gives us a 95 percent confidence interval of [.487, .582], which includes 50 percent, meaning it is quite plausible that we get this value even if nobody is making any persistent change in the population.&lt;/p&gt;
&lt;p&gt;The figure below shows estimates for the percent of the population giving different responses in the first two waves (&amp;ldquo;changing&amp;rdquo;), the percent of changers persisting, and, using those two values, the percent of the population making a persistent change, for the seven binary questions about abortion.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;abortion_plot.png&#34; alt=&#34;Abortion estimates&#34;&gt;&lt;/p&gt;
&lt;p&gt;What should be obvious from the figure is that almost nobody makes a persistent change in any of these views on abortion in the GSS panels. There is only real evidence of persistence for the questions about abortion in the case of rape and if a woman is poor and cannot afford another child. For both questions, the best estimate is that one percent of the population makes a persistent change in a two-year period. This is the pattern thing we find in our paper using a different method.&lt;/p&gt;
&lt;p&gt;This approach is easiest to justify with questions binary responses, where changes are always equal. Binary questions constitute about a third of GSS attitude questions and include questions about civil liberties, racial differences, laws, and suicide.&lt;/p&gt;
&lt;p&gt;If we make the assumption that all one-unit changes in ordinal responses are equal, we can extend this approach to non-binary items. This might or might not be a viable assumption, depending on the question, which we can return to later. For the non-binary case, the question is not whether the respondent says the same thing in waves 2 and 3 more than chance, but rather whether, at wave 3, the respondent is closer to their response at wave 2 than wave 1.&lt;/p&gt;
&lt;p&gt;The figure below considers seven questions about political views. It presents the same set of estimates for the proportion of the population giving different responses for waves 1 and 2, the proportion of &amp;ldquo;changers&amp;rdquo; who are closer to their wave 2 response than their wave 1 response at wave 3, and the estimated proportion of the population making a persisting change, based on those values. These quesitons all have between five and seven response options on an ordinal scale.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;poli_plot.png&#34; alt=&#34;Political ideology estimates&#34;&gt;&lt;/p&gt;
&lt;p&gt;Again, we see that for many of these questions, people who give different reports at waves 1 and 2 are as likely to be closer to their wave 1 response as their wave 2 response, which suggests the &amp;ldquo;settled dispositions&amp;rdquo; model is the more likely data-generating process. Because the scales have more potential values, the proportion of people giving different responses at waves 1 and 2 are higher than in the binary case, but there&amp;rsquo;s no more evidence of persistence than in the binary questions.&lt;/p&gt;
&lt;p&gt;Again, we reproduce one of the key findings of our paper: that there is very little evidence that American adults make persisting changes in their political views. Similar to the paper, there is some evidence that a small proportion of people change their political views.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re not willing to make the assumption that all one-unit changes in an ordinal scale are the same, we can collapse categories to measure more substantive changes. But I&amp;rsquo;m going to argue that you&amp;rsquo;re wasting your time. We can cut up the seven-point political views question in a number of ways, but I&amp;rsquo;ll feature three substantively interesting ones here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Seven separate values: Extremely Liberal, Liberal, Slightly Liberal, Moderate, Slightly Conservative, Conservative, Extremely Conservative&lt;/li&gt;
&lt;li&gt;Liberal/moderate/conservative: (Extremely Liberal, Liberal, Slightly Liberal), (Moderate), (Slightly Conservative, Conservative, Extremely Conservative)&lt;/li&gt;
&lt;li&gt;Clustering in middle: (Extremely Liberal, Liberal), (Slightly Liberal, Moderate, Slightly Conservative), (Conservative, Extremely Conservative)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below I plot these three approaches to the political views question.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;pv_plot.png&#34; alt=&#34;Political views estimates&#34;&gt;&lt;/p&gt;
&lt;p&gt;This approach shows us that grouping does not seem to affect our estimates of persistence for this question. Grouping in different ways decreases the amount of change in the population (since we are not capturing within-group changes), but does not affect our overall estimate of persistence in any substantial way. A structure that groups the three middle categories seems to provide the most evidence of persistence (though still not statistically significant at the alpha = .05 level), which is consistent with work that suggests that people who do not have clear views tend to select around the middle. Even then, the actual rate is very small.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve created a 
&lt;a href=&#34;https://krkiley.shinyapps.io/gss_panelchange/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shiny app&lt;/a&gt; where you can check out these estimates for every GSS question we explore in our paper, in which you can also compare by age group and panel. These results are remarkably consitent with what we see in the paper: change is very rare (often indistinguishable from 0) for views on gender, race, politics, law enforcement, religious beliefs, sex, and social trust. Categories that do show evidence for persistent change include confidence in institutional leadership and individual health and morale, but even these items show rates of less than five percent.&lt;/p&gt;
&lt;p&gt;The takeaway, just like the paper, is that persistent change in U.S. adults is exceedingly rare.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Several items in this and successive figures indicate a point estimate or confidence interval that suggests a negative proportion of persistence. This is conceptually problematic, but included for ease of presentation. These should be interpreted as reflecting no evidence of persistence. An item where the point estimate and confidence interval for the proportion of people persisting are entirely under 0 should be interpreted as indicating that people who change their response between waves 1 and 2 are more likely to be closer to their wave 1 response than their wave 2 response at wave 3. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Measuring Change and Stability in Personal Culture Using Panel Data</title>
      <link>https://krkiley.github.io/publication/measuring-change-and-stability-in-personal-culture-using-panel-data/</link>
      <pubDate>Tue, 18 Feb 2020 21:28:40 -0500</pubDate>
      <guid>https://krkiley.github.io/publication/measuring-change-and-stability-in-personal-culture-using-panel-data/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
